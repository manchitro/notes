# Overview
## Types of AI risk sources
### **Malicious use** - A person or group ***intentionally*** using AI for malicious purposes. 
Examples include:
#### **Bio-terrorism**
#### **Production and deployment of harmful AI agents**
- **Some people want AIs to supersede and replace humans because they believe that AIs are our intellectual successors and the next step in the cosmic evolution and humans should not interfere with this succession.**
#### **Persuasive AIs**
- Disinformation campaign and centralizing information
#### **Concentration of Power**
- Super powerful AIs in the hand of a totalitarian government may help them gain irreversible power which may be used against public interest.
- **This might block the moral progress of humanity**
	- Any values that is set into an AI model are hard to remove or amend. These AI systems in charge of withholding these values will not align with humanities values in the future because human morals are subject to change. This might create a blockade for moral progress.
### AI Race - Nations and Corporations engaged in competition to build powerful AI systems will neglect safety concerns
Analogous to the [Cold War](https://en.wikipedia.org/wiki/Cold_War). Examples include:
#### Military Arms Race
- Fully autonomous drones without human intervention are scalable, requires no endangerment of pilots and are invulnerable to jammers. This makes these more preferable to weapons that require human controller.
#### Cyberwarfare
- Reduces barrier to entry and makes more destruction.
- Unclear whether AI cyber defense or offense will be more potent. [Read](https://www.academia.edu/69485663/Cyberspace_in_Space_Fragmentation_Vulnerability_and_Uncertainty)
### Organizational Risks
### Rogue AIs