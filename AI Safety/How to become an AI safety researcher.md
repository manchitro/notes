[source: original article](https://www.lesswrong.com/posts/uKPtCoDesfawNfyJg/how-to-become-an-ai-safety-researcher) 
# Paths into AI safety
## What degrees did people get?
- - - 
- Mostly Mathematics and Computer Science.
- Research as undergrads in related fields
- [[Effective Altruism]] and [[Rationality as a discipline]]
- Additional Reading:
	- [[superintelligence-paths-dangers-strategies-by-nick-bostrom.pdf|Superintelligence]]
	- [PhD or programming? ](https://80000hours.org/podcast/episodes/olsson-and-ziegler-ml-engineering-and-safety/) 
	- [[human_compatible.pdf|Human Compatible]]
	- [[Christian-Alignment-Problem-Intro-and-Ch1.pdf|The Alignment Problem]]
## Skills
- - -
Technical skills
- programming
- mathematics (for theoretical work)
	- linear algebra
	- probability
	- calculus
- train/debug models and run experiments (for practical work)
- Reinforcement Learning
- Generally pytorch, numpy, pandas and matplotlib
- For NLP, [**Huggingface transformers** library](https://huggingface.co/docs/transformers/en/index)
- NLP safety work involves collecting data from humans
	- which means that frontend software development skills (**typescript, react**) are useful for making data collection websites
- For theoretical safety work:
	- coding and math is useful regardless
	- thorough knowledge over a reasonably broad range
		- ```"There is a mathematical skill of “given that I have this conjecture, how do I state a proof?”. Having knowledge of a lot of math can help with this because seemingly random math facts may be useful for constructing a proof."```
		- Economics
		- Certain parts of psychology
		- Areas of philosophy, specifically in philosophy of science, meaning and reference, knowledge (although this might be a minority view)
		- Dynamical systems and equilibria (possibly related to biology)
		- Cybernetics and information theory